import os
import json
import shutil
from datetime import datetime
from PIL import Image, PngImagePlugin
import hashlib
import logging

class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    RESET = '\033[0m'
    BOLD = '\033[1m'

def setup_logging(log_dir: str) -> logging.Logger:
    """ë¡œê¹… ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
    os.makedirs(log_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"image_processing_{timestamp}.log")
    
    logger = logging.getLogger("ImageProcessor")
    logger.setLevel(logging.INFO)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(message)s')
    console_handler.setFormatter(console_formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def log_message(logger: logging.Logger, message: str, status: str = "INFO"):
    """ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì½˜ì†”ê³¼ íŒŒì¼ì— ì¶œë ¥í•©ë‹ˆë‹¤"""
    status_indicators = {
        "INFO": f"{Colors.BLUE}ğŸ’¬ {Colors.RESET}",
        "SUCCESS": f"{Colors.GREEN}ğŸ’« {Colors.RESET}",
        "WARNING": f"{Colors.YELLOW}â­ {Colors.RESET}",
        "ERROR": f"{Colors.RED}âŒ {Colors.RESET}",
        "PROCESS": f"{Colors.BLUE}ğŸ’  {Colors.RESET}",
    }
    
    indicator = status_indicators.get(status, status_indicators["INFO"])
    console_message = f"{indicator} {message}"
    logger.info(message)
    print(console_message)

def calculate_file_hash(file_path: str) -> str:
    """íŒŒì¼ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def create_backup(file_path: str, backup_dir: str, logger: logging.Logger) -> None:
    """ì›ë³¸ íŒŒì¼ì„ ë°±ì—…í•©ë‹ˆë‹¤"""
    try:
        os.makedirs(backup_dir, exist_ok=True)
        filename = os.path.basename(file_path)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = os.path.join(backup_dir, f"{timestamp}_{filename}")
        shutil.copy2(file_path, backup_path)
        log_message(logger, f"ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_path}", "SUCCESS")
    except Exception as e:
        log_message(logger, f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}", "ERROR")
        raise

def process_image(image_path: str, max_size: int = 200, logger: logging.Logger = None) -> dict:
    """ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
    try:
        # ì´ë¯¸ì§€ ì—´ê¸°
        with Image.open(image_path) as img:
            # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘
            original_size = img.size
            original_format = img.format
            original_mode = img.mode
            
            # RGBA ëª¨ë“œë¡œ ë³€í™˜ (íˆ¬ëª… ë°°ê²½ ì§€ì›)
            if img.mode != 'RGBA':
                img = img.convert('RGBA')
            
            # ì´ë¯¸ì§€ê°€ max_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ì›ë³¸ í¬ê¸° ìœ ì§€
            if max(original_size) <= max_size:
                log_message(logger, f"ì´ë¯¸ì§€ê°€ {max_size}pxë³´ë‹¤ ì‘ì•„ ì›ë³¸ í¬ê¸° ìœ ì§€: {original_size}", "INFO")
                new_size = original_size
            else:
                # 1:1 ë¹„ìœ¨ë¡œ ìë¥´ê¸°
                min_dimension = min(original_size)
                left = (original_size[0] - min_dimension) // 2
                top = (original_size[1] - min_dimension) // 2
                right = left + min_dimension
                bottom = top + min_dimension
                
                img = img.crop((left, top, right, bottom))
                
                # ë¦¬ì‚¬ì´ì¦ˆ
                img = img.resize((max_size, max_size), Image.Resampling.LANCZOS)
                new_size = (max_size, max_size)
            
            # ë©”íƒ€ë°ì´í„° ì œê±°
            meta = PngImagePlugin.PngInfo()
            
            # ì €ì¥
            img.save(image_path, "PNG", pnginfo=meta)
            log_message(logger, f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {image_path}", "SUCCESS")
            
            # ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
            return {
                "original_size": original_size,
                "new_size": new_size,
                "original_format": original_format,
                "original_mode": original_mode,
                "new_format": "PNG",
                "new_mode": "RGBA",
                "processed_at": datetime.now().isoformat()
            }
            
    except Exception as e:
        log_message(logger, f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", "ERROR")
        raise

def main():
    # ê²½ë¡œ ì„¤ì •
    base_dir = os.path.dirname(os.path.abspath(__file__))
    source_dir = os.path.join(os.path.dirname(base_dir), "static", "img", "projects")
    data_dir = os.path.join(base_dir, "data")
    backup_dir = os.path.join(data_dir, "backups")
    log_dir = os.path.join(data_dir, "logs")
    processed_file = os.path.join(data_dir, "processed_images.json")
    
    # ë¡œê±° ì„¤ì •
    logger = setup_logging(log_dir)
    
    # ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
    if not os.path.exists(source_dir):
        log_message(logger, f"ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_dir}", "ERROR")
        return
    
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(data_dir, exist_ok=True)
    os.makedirs(backup_dir, exist_ok=True)
    
    # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ëª©ë¡ ë¡œë“œ
    processed_images = {}
    if os.path.exists(processed_file):
        with open(processed_file, 'r', encoding='utf-8') as f:
            processed_images = json.load(f)
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬
    for filename in os.listdir(source_dir):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
            image_path = os.path.join(source_dir, filename)
            
            # ì›ë³¸ íŒŒì¼ í•´ì‹œ ê³„ì‚°
            original_hash = calculate_file_hash(image_path)
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸ (íŒŒì¼ëª…ê³¼ í•´ì‹œë¡œ í™•ì¸)
            is_processed = False
            for hash_value, info in processed_images.items():
                if info['filename'] == filename and info['original_hash'] == original_hash:
                    is_processed = True
                    break
            
            if is_processed:
                continue
            
            log_message(logger, f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {filename}", "PROCESS")
            
            # ë°±ì—… ìƒì„±
            create_backup(image_path, backup_dir, logger)
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            process_result = process_image(image_path, logger=logger)
            
            # ì²˜ë¦¬ í›„ í•´ì‹œ ê³„ì‚°
            processed_hash = calculate_file_hash(image_path)
            
            # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
            processed_images[processed_hash] = {
                "filename": filename,
                "processed_at": datetime.now().isoformat(),
                "original_hash": original_hash,
                "process_details": process_result
            }
            
            # ì²˜ë¦¬ ê¸°ë¡ ì €ì¥
            with open(processed_file, 'w', encoding='utf-8') as f:
                json.dump(processed_images, f, indent=2, ensure_ascii=False)
            
    log_message(logger, "ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ", "SUCCESS")

if __name__ == "__main__":
    main() 